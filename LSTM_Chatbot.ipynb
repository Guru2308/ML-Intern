{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyrKOoLuk7Do",
        "outputId": "7db713fa-1c15-4f49-af2f-3881720d7f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30000, 13, 3027)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "lines = open('Chatbot Dataset/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')\n",
        "\n",
        "convers = open('Chatbot Dataset/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')\n",
        "\n",
        "\n",
        "exchn = []\n",
        "for conver in convers:\n",
        "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n",
        "\n",
        "diag = {}\n",
        "for line in lines:\n",
        "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
        "\n",
        "## delete\n",
        "del(lines, convers, conver, line)\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for conver in exchn:\n",
        "    for i in range(len(conver) - 1):\n",
        "        questions.append(diag[conver[i]])\n",
        "        answers.append(diag[conver[i+1]])\n",
        "\n",
        "## delete\n",
        "del(diag, exchn, conver, i)\n",
        "\n",
        "\n",
        "###############################\n",
        "#        max_len = 13         #\n",
        "###############################\n",
        "\n",
        "sorted_ques = []\n",
        "sorted_ans = []\n",
        "for i in range(len(questions)):\n",
        "    if len(questions[i]) < 13:\n",
        "        sorted_ques.append(questions[i])\n",
        "        sorted_ans.append(answers[i])\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
        "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
        "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
        "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
        "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
        "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
        "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
        "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
        "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
        "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
        "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
        "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
        "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
        "    return txt\n",
        "\n",
        "clean_ques = []\n",
        "clean_ans = []\n",
        "\n",
        "for line in sorted_ques:\n",
        "    clean_ques.append(clean_text(line))\n",
        "        \n",
        "for line in sorted_ans:\n",
        "    clean_ans.append(clean_text(line))\n",
        "\n",
        "\n",
        "\n",
        "## delete\n",
        "del(answers, questions, line)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
        "\n",
        "\n",
        "\n",
        "###############################\n",
        "#                             #\n",
        "###############################\n",
        "\n",
        "del(sorted_ans, sorted_ques)\n",
        "\n",
        "\n",
        "## trimming\n",
        "clean_ans=clean_ans[:30000]\n",
        "clean_ques=clean_ques[:30000]\n",
        "## delete\n",
        "\n",
        "\n",
        "###  count occurences ###\n",
        "word2count = {}\n",
        "\n",
        "for line in clean_ques:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in clean_ans:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "## delete\n",
        "del(word, line)\n",
        "\n",
        "\n",
        "###  remove less frequent ###\n",
        "thresh = 5\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1\n",
        "        \n",
        "## delete\n",
        "del(word2count, word, count, thresh)       \n",
        "del(word_num)        \n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
        "\n",
        "\n",
        "\n",
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1\n",
        "    \n",
        "    \n",
        "\n",
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0\n",
        "\n",
        "## delete\n",
        "del(token, tokens) \n",
        "del(x)\n",
        "\n",
        "### inv answers dict ###\n",
        "inv_vocab = {w:v for v, w in vocab.items()}\n",
        "\n",
        "\n",
        "\n",
        "## delete\n",
        "del(i)\n",
        "\n",
        "\n",
        "\n",
        "encoder_inp = []\n",
        "for line in clean_ques:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)\n",
        "\n",
        "decoder_inp = []\n",
        "for line in clean_ans:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)\n",
        "\n",
        "### delete\n",
        "del(clean_ans, clean_ques, line, lst, word)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n",
        "\n",
        "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "del(i)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
        "\n",
        "\n",
        "\n",
        "print(decoder_final_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csPnVtT390r7",
        "outputId": "d2c45d7b-800e-41da-9e74-8565d0fc0076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 112s 116ms/step - loss: 3.0979 - acc: 0.4937\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 101s 108ms/step - loss: 2.7331 - acc: 0.5328\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 100s 106ms/step - loss: 2.5999 - acc: 0.5433\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 99s 106ms/step - loss: 2.5260 - acc: 0.5477\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 109s 116ms/step - loss: 2.4675 - acc: 0.5511\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 111s 118ms/step - loss: 2.4175 - acc: 0.5540\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 108s 115ms/step - loss: 2.3709 - acc: 0.5562\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 109s 116ms/step - loss: 2.3236 - acc: 0.5583\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 107s 114ms/step - loss: 2.2793 - acc: 0.5607\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 110s 118ms/step - loss: 2.2393 - acc: 0.5630\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 106s 113ms/step - loss: 2.1937 - acc: 0.5653\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 105s 112ms/step - loss: 2.1489 - acc: 0.5679\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 109s 116ms/step - loss: 2.1072 - acc: 0.5709\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 103s 110ms/step - loss: 2.0673 - acc: 0.5746\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 100s 107ms/step - loss: 2.0271 - acc: 0.5779\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 117s 124ms/step - loss: 1.9895 - acc: 0.5819\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 89s 95ms/step - loss: 1.9522 - acc: 0.5863\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 94s 101ms/step - loss: 1.9157 - acc: 0.5907\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 110s 118ms/step - loss: 1.8804 - acc: 0.5957\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 105s 112ms/step - loss: 1.8462 - acc: 0.6007\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 94s 100ms/step - loss: 1.8119 - acc: 0.6059\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 95s 102ms/step - loss: 1.7796 - acc: 0.6108\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 89s 95ms/step - loss: 1.7479 - acc: 0.6166\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 89s 95ms/step - loss: 1.7179 - acc: 0.6215\n",
            "Epoch 25/50\n",
            "792/938 [========================>.....] - ETA: 14s - loss: 1.6798 - acc: 0.6282"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19964\\3371599046.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_inp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_final_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32mc:\\Users\\kisha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "\n",
        "enc_inp = Input(shape=(13, ))\n",
        "dec_inp = Input(shape=(13, ))\n",
        "\n",
        "\n",
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
        "                  input_length=13,\n",
        "                  trainable=True                  \n",
        "                  )\n",
        "\n",
        "\n",
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]\n",
        "\n",
        "\n",
        "\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
        "\n",
        "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU5cNEft90lz"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "\n",
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "\n",
        "\n",
        "# decoder Model\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
        "                                    initial_state=decoder_states_inputs)\n",
        "\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
        "                                      [decoder_outputs]+ decoder_states)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcCLNLqRme-L",
        "outputId": "5716c5f3-0309-4414-a7c1-1c5cd462ae16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1561
        },
        "id": "DtzOswvb90jC",
        "outputId": "e5bde2cf-d562-45aa-d4f3-d3283ca06195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "#       start chatting ver. 1.0          #\n",
            "##########################################\n",
            "you : hello\n",
            "1/1 [==============================] - 1s 651ms/step\n",
            "1/1 [==============================] - 0s 311ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "chatbot attention :  i am sorry \n",
            "==============================================\n",
            "you : hi\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "chatbot attention :  hi \n",
            "==============================================\n",
            "you : hello\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "chatbot attention :  i am sorry \n",
            "==============================================\n",
            "you : who are you?\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "chatbot attention :  i am <OUT> i am here \n",
            "==============================================\n",
            "you : what are your views about privatization\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "chatbot attention :  i am not saying i can get some sleep <OUT> <OUT> \n",
            "==============================================\n",
            "you : fuck off\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "chatbot attention :  i will give you a chance to find the car i \n",
            "==============================================\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-edff408c4ef3>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprepro1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m## prepro1 = \"Hello\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "print(\"##########################################\")\n",
        "print(\"#       start chatting ver. 1.0          #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    prepro1  = input(\"you : \")\n",
        "    ## prepro1 = \"Hello\"\n",
        "\n",
        "    prepro1 = clean_text(prepro1)\n",
        "    ## prepro1 = \"hello\"\n",
        "\n",
        "    prepro = [prepro1]\n",
        "    ## prepro1 = [\"hello\"]\n",
        "\n",
        "    txt = []\n",
        "    for x in prepro:\n",
        "        # x = \"hello\"\n",
        "        lst = []\n",
        "        for y in x.split():\n",
        "            ## y = \"hello\"\n",
        "            try:\n",
        "                lst.append(vocab[y])\n",
        "                ## vocab['hello'] = 454\n",
        "            except:\n",
        "                lst.append(vocab['<OUT>'])\n",
        "        txt.append(lst)\n",
        "\n",
        "    ## txt = [[454]]\n",
        "    txt = pad_sequences(txt, 13, padding='post')\n",
        "\n",
        "    ## txt = [[454,0,0,0,.........13]]\n",
        "\n",
        "    stat = enc_model.predict( txt )\n",
        "\n",
        "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "     ##   empty_target_seq = [0]\n",
        "\n",
        "\n",
        "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "    ##    empty_target_seq = [255]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "\n",
        "        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
        "        decoder_concat_input = dense(dec_outputs)\n",
        "        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
        "\n",
        "        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "        ## sampled_word_index = [2]\n",
        "\n",
        "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "        ## inv_vocab[2] = 'hi'\n",
        "        ## sampled_word = 'hi '\n",
        "\n",
        "        if sampled_word != '<EOS> ':\n",
        "            decoded_translation += sampled_word  \n",
        "\n",
        "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "            stop_condition = True \n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        ## <SOS> - > hi\n",
        "        ## hi --> <EOS>\n",
        "        stat = [h, c]  \n",
        "\n",
        "    print(\"chatbot attention : \", decoded_translation )\n",
        "    print(\"==============================================\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MILM2FKpCRx"
      },
      "outputs": [],
      "source": [
        "model.save('saved_model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlMLUSCF90gA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sBxAduq90dB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzV2WqoE90aB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ile7D0S790Wt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAxKPUav90UF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aspjrz8O90RA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oft7Q0SE90OI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy1q8h7t90LI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag7nKMAb90EP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
